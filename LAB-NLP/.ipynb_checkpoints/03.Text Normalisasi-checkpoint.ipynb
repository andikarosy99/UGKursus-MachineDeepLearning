{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalisasi\n",
    "Pengangantian token  ke dalam bentuk resmi sehingga kita dapat menggabungkannya kedalam berbagai macam variasi dari sebuah kata\n",
    "\n",
    "Contohnya:\n",
    "    \n",
    "- lowercasing\n",
    "- stemming\n",
    "- American-to-British mapping\n",
    "- synonym mapping\n",
    "\n",
    "## Stemming\n",
    "**Stemming** adalah proses untuk mereduksi kata ke dalam sederhana yang disebut stem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cook\n",
      "cookeri\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print (stemmer.stem('cooking'))\n",
    "print (stemmer.stem('cookery'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menggunakan algoritma PortStremer. Terdapat beberapa algoritma lain yang disediakan oleh NLTK seperti:\n",
    "- LancasterStemmer yang berasala dari Lancaster University\n",
    "- RegexpStemmer yang biasa berfungsi untuk menghapus prefix atau sufix yang sesuai dengan template \n",
    "- SnowballStemmer yang mendukung 13 bahasa non-inggris \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cook\n",
      "cookery\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "print (stemmer.stem('cooking'))\n",
    "print (stemmer.stem('cookery'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cook\n",
      "cookery\n",
      "leside\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmer = RegexpStemmer('ing')\n",
    "print (stemmer.stem('cooking'))\n",
    "print (stemmer.stem('cookery'))\n",
    "print (stemmer.stem('ingleside'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "SnowballStemmer.languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hola'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_stemmer = SnowballStemmer('english')\n",
    "spanish_stemmer.stem('hola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hola'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_stemmer=SnowballStemmer('dutch')\n",
    "dutch_stemmer.stem('hola')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization \n",
    "Lemma adalah akar kata. Salah satu kamus yang dapat digunakan untuk mencari akar kata adalah Wordnet. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "run\n",
      "thing\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print (lemmatizer.lemmatize('running'))\n",
    "print (lemmatizer.lemmatize('running', pos='v'))\n",
    "print (lemmatizer.lemmatize('things'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perbedaan antara stemmin dengan lematization adalah sebagai berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "believ\n",
      "belief\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print (stemmer.stem('believes'))\n",
    "print (lemmatizer.lemmatize('believes'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penggantian Kata menggunakan matching regular expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "replacement_patterns = [\n",
    "(r'won\\'t', 'will not'),\n",
    "(r'can\\'t', 'cannot'),\n",
    "(r'i\\'m', 'i am'),\n",
    "(r'ain\\'t', 'is not'),\n",
    "(r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "(r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "(r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "(r'(\\w+)\\'s', '\\g<1> is'),\n",
    "(r'(\\w+)\\'re', '\\g<1> are'),\n",
    "(r'(\\w+)\\'d', '\\g<1> would')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [(re.compile(regex), repl) for (regex, repl) in replacement_patterns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cannot learn NLP'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = \"can't learn NLP\"\n",
    "for (pattern, repl) in patterns:\n",
    "    source = re.sub(pattern, repl, source)\n",
    "source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Checker \n",
    "\n",
    "Kita dapat menggunakan spelling checker untuk mendapatkan hasil yang lebih baik. Salah satunya dengan menggunakan ``enchant`` yang merupakan library spelling checker dari AbiWord (salah satu software open source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cookbook'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from replacers import SpellingReplacer\n",
    "replacer = SpellingReplacer()\n",
    "replacer.replace('cookbok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en_US']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import enchant\n",
    "enchant.list_languages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhatikan penggunaan kamus yang akan digunakan karenan setiap kamus akan memiliki nilai yang berbeda-beda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "dUS = enchant.Dict('en_US')\n",
    "print (dUS.check('theater'))\n",
    "dGB = enchant.Dict('en_GB')\n",
    "print (dGB.check('theater'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theater\n",
      "theater\n"
     ]
    }
   ],
   "source": [
    "us_replacer = SpellingReplacer('en_US')\n",
    "print (us_replacer.replace('theater'))\n",
    "gb_replacer = SpellingReplacer('en_GB')\n",
    "print (gb_replacer.replace('theater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling checker menggunakan definisi kita\n",
    "\n",
    "Kita dapat membuat kamus sendiri untuk melalukan penggantian kata seperti spelling checker. Dengan membuat class sebagai berikut:\n",
    "\n",
    "``class WordReplacer(object):\n",
    "    def __init__(self, word_map):\n",
    "        self.word_map = word_map\n",
    "    def replace(self, word):\n",
    "        return self.word_map.get(word, word)``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-301b62921fd3>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-301b62921fd3>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print replacer.replace('yg')\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from replacers import WordReplacer\n",
    "replacer = WordReplacer({'yg': 'yang'})\n",
    "print (replacer.replace('yg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
